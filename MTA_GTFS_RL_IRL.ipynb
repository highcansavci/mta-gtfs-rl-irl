{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Project Desciption"
      ],
      "metadata": {
        "id": "knOsuH-MSxhQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project explores the application of Reinforcement Learning (RL) and Inverse Reinforcement Learning (IRL) to optimize bus transit schedules using real-world transit data. The primary objective is to develop a predictive model that can generate efficient bus schedules, reduce delays, and improve the reliability of public transportation services. By combining RL, which learns optimal actions based on rewards, with IRL, which derives rewards from observed behavior, this model aims to achieve a balance between planned schedules and realistic, adaptive operations based on historical patterns. The project utilizes data from the New York City MTA-GTFS bus line, modeling bus behavior and transit flow to simulate and predict optimal routes."
      ],
      "metadata": {
        "id": "f056d-_gS09W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Necessary Packages and Unzip the Data"
      ],
      "metadata": {
        "id": "CZPlTw95n9DU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Description: In this segment, we install and import the necessary libraries for data analysis, reinforcement learning, and handling of neural networks. Essential libraries include stable-baselines3 for RL models, torch for deep learning, and pandas for data handling. We then extract the compressed data file containing historical bus transit records, which will serve as the basis for training and testing the models.\n",
        "* Purpose: Set up the working environment with all dependencies to ensure smooth operation throughout the analysis and modeling stages."
      ],
      "metadata": {
        "id": "jxKNbfgHSYWk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stable-baselines3[extra]\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import zipfile\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import gym\n",
        "from gym import spaces\n",
        "from torch.distributions import Categorical\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from stable_baselines3.common.callbacks import EvalCallback\n",
        "\n",
        "# Unzip the data\n",
        "with zipfile.ZipFile('/content/mta_bus_data.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('.')"
      ],
      "metadata": {
        "id": "VJyQHc-KoGKU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e4e1401-f85b-4cea-8547-0e4b51c54a7a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: stable-baselines3[extra] in /usr/local/lib/python3.10/dist-packages (2.3.2)\n",
            "Requirement already satisfied: gymnasium<0.30,>=0.28.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (1.26.4)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.5.0+cu121)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (3.1.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (3.8.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (4.10.0.84)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.6.1)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.17.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (5.9.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (4.66.6)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (13.9.3)\n",
            "Requirement already satisfied: shimmy~=1.3.0 in /usr/local/lib/python3.10/dist-packages (from shimmy[atari]~=1.3.0; extra == \"extra\"->stable-baselines3[extra]) (1.3.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (10.4.0)\n",
            "Requirement already satisfied: autorom~=0.6.1 in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (0.6.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (8.1.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (2.32.3)\n",
            "Requirement already satisfied: AutoROM.accept-rom-license in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (0.6.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra]) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra]) (0.0.4)\n",
            "Requirement already satisfied: ale-py~=0.8.1 in /usr/local/lib/python3.10/dist-packages (from shimmy[atari]~=1.3.0; extra == \"extra\"->stable-baselines3[extra]) (0.8.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.64.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,<5.0.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.13->stable-baselines3[extra]) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3[extra]) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3[extra]) (2024.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->stable-baselines3[extra]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->stable-baselines3[extra]) (2.18.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from ale-py~=0.8.1->shimmy[atari]~=1.3.0; extra == \"extra\"->stable-baselines3[extra]) (6.4.5)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading"
      ],
      "metadata": {
        "id": "UbijoL3unlvB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Description: Here, we load the bus transit dataset into a pandas DataFrame for processing. The dataset contains information such as vehicle IDs, timestamps, stop sequences, distances traveled, and stop IDs. Each entry represents a record of a bus’s journey at a specific time.\n",
        "* Purpose: This segment is essential for loading the raw data, which provides the foundational information needed for transit modeling and allows us to inspect the structure and contents of the dataset."
      ],
      "metadata": {
        "id": "s1qibcTWSbx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/B63-2011-04-03_2011-05-03.csv')\n",
        "df"
      ],
      "metadata": {
        "id": "WuNd4gxT_5TT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 791
        },
        "outputId": "502636c2-260b-4dbe-cb63-c4bc0de08d16"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        vehicle_id            timestamp   latitude  longitude        phase  \\\n",
              "0             7573  2011-04-16 01:02:41  40.612648 -74.033723  IN_PROGRESS   \n",
              "1             7573  2011-04-16 01:03:16  40.613071 -74.033353  IN_PROGRESS   \n",
              "2             7573  2011-04-16 01:03:50  40.614715 -74.032055  IN_PROGRESS   \n",
              "3             7573  2011-04-16 01:04:09  40.617474 -74.030490  IN_PROGRESS   \n",
              "4             7573  2011-04-16 01:04:40  40.621249 -74.028916  IN_PROGRESS   \n",
              "...            ...                  ...        ...        ...          ...   \n",
              "840935        7586  2011-04-23 01:22:21  40.648513 -74.006835  IN_PROGRESS   \n",
              "840936        7586  2011-04-23 01:24:05  40.647063 -74.008340  IN_PROGRESS   \n",
              "840937        7586  2011-04-23 01:25:17  40.643003 -74.012593  IN_PROGRESS   \n",
              "840938        7586  2011-04-23 01:25:26  40.642570 -74.012877  IN_PROGRESS   \n",
              "840939        7586  2011-04-23 01:37:37  40.614123 -74.032948  IN_PROGRESS   \n",
              "\n",
              "                                   trip_id  direction_id  \\\n",
              "0       20110403AD_004000_B63_0089_B63_101             0   \n",
              "1       20110403AD_004000_B63_0089_B63_101             0   \n",
              "2       20110403AD_004000_B63_0089_B63_101             0   \n",
              "3       20110403AD_004000_B63_0089_B63_101             0   \n",
              "4       20110403AD_004000_B63_0089_B63_101             0   \n",
              "...                                    ...           ...   \n",
              "840935  20110403JA_149500_B63_0002_B63_129             1   \n",
              "840936  20110403JA_149500_B63_0002_B63_129             1   \n",
              "840937  20110403JA_149500_B63_0002_B63_129             1   \n",
              "840938  20110403JA_149500_B63_0002_B63_129             1   \n",
              "840939  20110403JA_149500_B63_0002_B63_129             1   \n",
              "\n",
              "                              trip_headsign  shape_dist_traveled  stop_id  \\\n",
              "0       B63 PIER 6 BKLYN BRIDGE PK via 5 AV           299.381043   305334   \n",
              "1       B63 PIER 6 BKLYN BRIDGE PK via 5 AV           357.314663   305335   \n",
              "2       B63 PIER 6 BKLYN BRIDGE PK via 5 AV           570.261417   308130   \n",
              "3       B63 PIER 6 BKLYN BRIDGE PK via 5 AV           898.529204   305338   \n",
              "4       B63 PIER 6 BKLYN BRIDGE PK via 5 AV          1322.867866   305341   \n",
              "...                                     ...                  ...      ...   \n",
              "840935      B63 BAY RIDGE SHORE RD via 5 AV          6822.575276   308337   \n",
              "840936      B63 BAY RIDGE SHORE RD via 5 AV          7029.367300   305442   \n",
              "840937      B63 BAY RIDGE SHORE RD via 5 AV          7608.351514   305446   \n",
              "840938      B63 BAY RIDGE SHORE RD via 5 AV          7661.100290   305446   \n",
              "840939      B63 BAY RIDGE SHORE RD via 5 AV         11367.676817   306940   \n",
              "\n",
              "        stop_sequence  dist_from_stop  \n",
              "0                   2       39.875024  \n",
              "1                   3      158.012705  \n",
              "2                   4      173.253540  \n",
              "3                   5      130.538314  \n",
              "4                   7      189.051827  \n",
              "...               ...             ...  \n",
              "840935             34      123.612851  \n",
              "840936             35      151.892403  \n",
              "840937             38      206.599373  \n",
              "840938             38      153.850597  \n",
              "840939             55      196.952104  \n",
              "\n",
              "[840940 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-daea0837-d08b-49fb-98cf-61387263461b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>vehicle_id</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>phase</th>\n",
              "      <th>trip_id</th>\n",
              "      <th>direction_id</th>\n",
              "      <th>trip_headsign</th>\n",
              "      <th>shape_dist_traveled</th>\n",
              "      <th>stop_id</th>\n",
              "      <th>stop_sequence</th>\n",
              "      <th>dist_from_stop</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7573</td>\n",
              "      <td>2011-04-16 01:02:41</td>\n",
              "      <td>40.612648</td>\n",
              "      <td>-74.033723</td>\n",
              "      <td>IN_PROGRESS</td>\n",
              "      <td>20110403AD_004000_B63_0089_B63_101</td>\n",
              "      <td>0</td>\n",
              "      <td>B63 PIER 6 BKLYN BRIDGE PK via 5 AV</td>\n",
              "      <td>299.381043</td>\n",
              "      <td>305334</td>\n",
              "      <td>2</td>\n",
              "      <td>39.875024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7573</td>\n",
              "      <td>2011-04-16 01:03:16</td>\n",
              "      <td>40.613071</td>\n",
              "      <td>-74.033353</td>\n",
              "      <td>IN_PROGRESS</td>\n",
              "      <td>20110403AD_004000_B63_0089_B63_101</td>\n",
              "      <td>0</td>\n",
              "      <td>B63 PIER 6 BKLYN BRIDGE PK via 5 AV</td>\n",
              "      <td>357.314663</td>\n",
              "      <td>305335</td>\n",
              "      <td>3</td>\n",
              "      <td>158.012705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7573</td>\n",
              "      <td>2011-04-16 01:03:50</td>\n",
              "      <td>40.614715</td>\n",
              "      <td>-74.032055</td>\n",
              "      <td>IN_PROGRESS</td>\n",
              "      <td>20110403AD_004000_B63_0089_B63_101</td>\n",
              "      <td>0</td>\n",
              "      <td>B63 PIER 6 BKLYN BRIDGE PK via 5 AV</td>\n",
              "      <td>570.261417</td>\n",
              "      <td>308130</td>\n",
              "      <td>4</td>\n",
              "      <td>173.253540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7573</td>\n",
              "      <td>2011-04-16 01:04:09</td>\n",
              "      <td>40.617474</td>\n",
              "      <td>-74.030490</td>\n",
              "      <td>IN_PROGRESS</td>\n",
              "      <td>20110403AD_004000_B63_0089_B63_101</td>\n",
              "      <td>0</td>\n",
              "      <td>B63 PIER 6 BKLYN BRIDGE PK via 5 AV</td>\n",
              "      <td>898.529204</td>\n",
              "      <td>305338</td>\n",
              "      <td>5</td>\n",
              "      <td>130.538314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7573</td>\n",
              "      <td>2011-04-16 01:04:40</td>\n",
              "      <td>40.621249</td>\n",
              "      <td>-74.028916</td>\n",
              "      <td>IN_PROGRESS</td>\n",
              "      <td>20110403AD_004000_B63_0089_B63_101</td>\n",
              "      <td>0</td>\n",
              "      <td>B63 PIER 6 BKLYN BRIDGE PK via 5 AV</td>\n",
              "      <td>1322.867866</td>\n",
              "      <td>305341</td>\n",
              "      <td>7</td>\n",
              "      <td>189.051827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>840935</th>\n",
              "      <td>7586</td>\n",
              "      <td>2011-04-23 01:22:21</td>\n",
              "      <td>40.648513</td>\n",
              "      <td>-74.006835</td>\n",
              "      <td>IN_PROGRESS</td>\n",
              "      <td>20110403JA_149500_B63_0002_B63_129</td>\n",
              "      <td>1</td>\n",
              "      <td>B63 BAY RIDGE SHORE RD via 5 AV</td>\n",
              "      <td>6822.575276</td>\n",
              "      <td>308337</td>\n",
              "      <td>34</td>\n",
              "      <td>123.612851</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>840936</th>\n",
              "      <td>7586</td>\n",
              "      <td>2011-04-23 01:24:05</td>\n",
              "      <td>40.647063</td>\n",
              "      <td>-74.008340</td>\n",
              "      <td>IN_PROGRESS</td>\n",
              "      <td>20110403JA_149500_B63_0002_B63_129</td>\n",
              "      <td>1</td>\n",
              "      <td>B63 BAY RIDGE SHORE RD via 5 AV</td>\n",
              "      <td>7029.367300</td>\n",
              "      <td>305442</td>\n",
              "      <td>35</td>\n",
              "      <td>151.892403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>840937</th>\n",
              "      <td>7586</td>\n",
              "      <td>2011-04-23 01:25:17</td>\n",
              "      <td>40.643003</td>\n",
              "      <td>-74.012593</td>\n",
              "      <td>IN_PROGRESS</td>\n",
              "      <td>20110403JA_149500_B63_0002_B63_129</td>\n",
              "      <td>1</td>\n",
              "      <td>B63 BAY RIDGE SHORE RD via 5 AV</td>\n",
              "      <td>7608.351514</td>\n",
              "      <td>305446</td>\n",
              "      <td>38</td>\n",
              "      <td>206.599373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>840938</th>\n",
              "      <td>7586</td>\n",
              "      <td>2011-04-23 01:25:26</td>\n",
              "      <td>40.642570</td>\n",
              "      <td>-74.012877</td>\n",
              "      <td>IN_PROGRESS</td>\n",
              "      <td>20110403JA_149500_B63_0002_B63_129</td>\n",
              "      <td>1</td>\n",
              "      <td>B63 BAY RIDGE SHORE RD via 5 AV</td>\n",
              "      <td>7661.100290</td>\n",
              "      <td>305446</td>\n",
              "      <td>38</td>\n",
              "      <td>153.850597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>840939</th>\n",
              "      <td>7586</td>\n",
              "      <td>2011-04-23 01:37:37</td>\n",
              "      <td>40.614123</td>\n",
              "      <td>-74.032948</td>\n",
              "      <td>IN_PROGRESS</td>\n",
              "      <td>20110403JA_149500_B63_0002_B63_129</td>\n",
              "      <td>1</td>\n",
              "      <td>B63 BAY RIDGE SHORE RD via 5 AV</td>\n",
              "      <td>11367.676817</td>\n",
              "      <td>306940</td>\n",
              "      <td>55</td>\n",
              "      <td>196.952104</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>840940 rows × 12 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-daea0837-d08b-49fb-98cf-61387263461b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-daea0837-d08b-49fb-98cf-61387263461b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-daea0837-d08b-49fb-98cf-61387263461b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-40461c9e-f5a1-4610-82ed-033ea6d51ba7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-40461c9e-f5a1-4610-82ed-033ea6d51ba7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-40461c9e-f5a1-4610-82ed-033ea6d51ba7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_6d4d76a0-998d-4d5a-a10c-27d4942b85dd\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_6d4d76a0-998d-4d5a-a10c-27d4942b85dd button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "BhYNujecTGFb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Description: This segment prepares the transit data for use in machine learning models by cleaning and engineering relevant features. Key steps include:\n",
        "1.   Timestamp Standardization: Converts timestamps into a consistent format for time-based calculations.\n",
        "2.   Sorting and Handling Missing Values: Organizes data sequentially by vehicle ID and timestamp, and fills missing values in columns like stop_id to maintain data continuity.\n",
        "3.   Feature Engineering:\n",
        "Calculates distance_traveled and speed between stops to capture movement characteristics.\n",
        "Encodes bus phase statuses (e.g., \"IN_PROGRESS\") into numerical values, making them compatible with machine learning models.\n",
        "Generates temporal features (e.g., hour of day, day of the week) to capture\n",
        "potential patterns in transit behavior.\n",
        "\n",
        "* Purpose: Data preprocessing is crucial for converting raw data into a structured format that machine learning models can interpret. This step enriches the dataset with additional features, improving model accuracy and enabling better predictions."
      ],
      "metadata": {
        "id": "RixFhrsHTIcz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert Timestamps: Parse the timestamp column to a standard datetime format, enabling sorting and time-based feature engineering.\n",
        "# Sort by Vehicle ID and Time: Sort data by vehicle_id and timestamp to maintain sequential integrity for each bus, essential for trajectory tracking.\n",
        "# Handle Missing Values: Fill missing values in columns like stop_id, stop_sequence, and dist_from_stop based on neighboring entries or interpolate where needed.\n",
        "# Engineer Distance and Speed Features:\n",
        "#     Calculate distance_traveled using shape_dist_traveled differences between consecutive rows per vehicle_id.\n",
        "#     Derive speed based on time differences and distance, useful for analyzing delays and detecting congested routes.\n",
        "# Categorize Phases: Convert the phase column to binary or numerical indicators (e.g., IN_PROGRESS = 1, LAYOVER_DURING = 0) to ease RL state encoding.\n",
        "# Generate Sequential Trip Data: Group by trip_id and calculate statistics, such as average travel time per trip, providing a target for RL\n",
        "\n",
        "def preprocess_data(df):\n",
        "    \"\"\"Preprocess the transit data for RL-IRL environments\"\"\"\n",
        "    # Create a copy to avoid modifications to original data\n",
        "    df = df.copy()\n",
        "\n",
        "    # Convert timestamp to datetime\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "\n",
        "    # Sort by vehicle and time\n",
        "    df = df.sort_values(['vehicle_id', 'timestamp'])\n",
        "\n",
        "    # Forward fill missing values\n",
        "    df['stop_id'] = df['stop_id'].ffill()\n",
        "    df['stop_sequence'] = df['stop_sequence'].ffill()\n",
        "    df['dist_from_stop'] = df['dist_from_stop'].ffill()\n",
        "\n",
        "    # Calculate time differences and speeds\n",
        "    df['time_diff'] = df.groupby('vehicle_id')['timestamp'].diff().dt.total_seconds()\n",
        "    df['distance_traveled'] = df.groupby('vehicle_id')['shape_dist_traveled'].diff()\n",
        "\n",
        "    # Calculate speed (meters per second)\n",
        "    df['speed'] = (df['distance_traveled'] / df['time_diff']).replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "    # Fill NaN values with appropriate defaults\n",
        "    df['speed'] = df['speed'].fillna(0)\n",
        "    df['time_diff'] = df['time_diff'].fillna(0)\n",
        "    df['distance_traveled'] = df['distance_traveled'].fillna(0)\n",
        "\n",
        "    # Convert phase to numerical\n",
        "    phase_map = {'IN_PROGRESS': 1, 'LAYOVER_DURING': 0}\n",
        "    df['phase'] = df['phase'].map(phase_map).fillna(-1)\n",
        "\n",
        "    # Add temporal features\n",
        "    df['hour'] = df['timestamp'].dt.hour\n",
        "    df['day'] = df['timestamp'].dt.dayofweek\n",
        "    df['week'] = df['timestamp'].dt.isocalendar().week\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "8YL2h39mn5Js",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91870014-8f05-4cf6-a7f5-ead5e5d46575"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Feature Engineering and State Representation\n",
        "# Now that the data is preprocessed, we can proceed with feature engineering:\n",
        "# Key Steps for Step 2:\n",
        "#     Define State Features: Use features like latitude, longitude, shape_dist_traveled, phase, and stop_id as core components of each bus’s state.\n",
        "#     Create Time-Based Features: Break down timestamp into hour, day, and week features to capture temporal patterns, such as peak hours or weekday/weekend trends.\n",
        "#     Normalize Numerical Features: Scale features like distance_traveled and speed to a range suitable for RL models.\n",
        "#     Encode Categorical Data: Convert phase, direction_id, and trip_headsign into one-hot or embedding representations for easier integration into RL models.\n",
        "\n",
        "\n",
        "def feature_engineer(df):\n",
        "    \"\"\"Engineer features for the RL environment\"\"\"\n",
        "    processed_df = df.copy()\n",
        "\n",
        "    # Numerical features to normalize\n",
        "    numerical_cols = [\n",
        "        'latitude', 'longitude', 'shape_dist_traveled',\n",
        "        'dist_from_stop', 'distance_traveled', 'speed',\n",
        "        'time_diff'\n",
        "    ]\n",
        "\n",
        "    # Normalize numerical features\n",
        "    scaler = StandardScaler()\n",
        "    processed_df[numerical_cols] = scaler.fit_transform(processed_df[numerical_cols])\n",
        "\n",
        "    # One-hot encode categorical variables\n",
        "    categorical_cols = ['direction_id', 'trip_headsign']\n",
        "    processed_df = pd.get_dummies(processed_df, columns=categorical_cols, prefix=categorical_cols)\n",
        "\n",
        "    # Create hour sine and cosine features for cyclical time representation\n",
        "    processed_df['hour_sin'] = np.sin(2 * np.pi * processed_df['hour']/24)\n",
        "    processed_df['hour_cos'] = np.cos(2 * np.pi * processed_df['hour']/24)\n",
        "\n",
        "    # Create day sine and cosine features\n",
        "    processed_df['day_sin'] = np.sin(2 * np.pi * processed_df['day']/7)\n",
        "    processed_df['day_cos'] = np.cos(2 * np.pi * processed_df['day']/7)\n",
        "\n",
        "    return processed_df"
      ],
      "metadata": {
        "id": "GoOPWn7ho-v7"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Environment Setup for RL and IRL Modeling"
      ],
      "metadata": {
        "id": "HuNVZBWCT-8B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Description: In this part, we create a custom environment tailored for RL and IRL, which simulates the bus transit system. This environment allows RL agents to interact with the transit data, selecting actions that represent bus route decisions and observing the results. We define state representations (such as bus locations and times) and actions (e.g., adjust speed or direction).\n",
        "* Purpose: Establishing an RL/IRL environment is fundamental for training agents on the transit data. It serves as a virtual platform where models learn to make optimal scheduling decisions based on reward functions, ultimately leading to efficient bus routing strategies."
      ],
      "metadata": {
        "id": "Qw4mzHx0T5Eb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment Definition"
      ],
      "metadata": {
        "id": "OftZ-n_GNFdR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiBusRouteEnv(gym.Env):\n",
        "    \"\"\"Multi-bus transit system environment\"\"\"\n",
        "\n",
        "    def __init__(self, data, time_limit=1000):\n",
        "        super(MultiBusRouteEnv, self).__init__()\n",
        "\n",
        "        # Preprocess and engineer features\n",
        "        self.data = preprocess_data(data)\n",
        "        self.processed_data = feature_engineer(self.data)\n",
        "\n",
        "        # Group data by vehicle_id\n",
        "        self.buses_data = dict(tuple(self.processed_data.groupby('vehicle_id')))\n",
        "        self.bus_ids = list(self.buses_data.keys())\n",
        "        self.num_buses = len(self.bus_ids)\n",
        "\n",
        "        # Define feature columns for state space\n",
        "        self.state_columns = [\n",
        "            'latitude', 'longitude', 'shape_dist_traveled',\n",
        "            'dist_from_stop', 'distance_traveled', 'speed',\n",
        "            'hour_sin', 'hour_cos', 'day_sin', 'day_cos',\n",
        "            'phase'\n",
        "        ] + [col for col in self.processed_data.columns if 'direction_id_' in col or 'trip_headsign_' in col]\n",
        "\n",
        "        # Flattened action space for all buses: 2 actions (speed adjustment, stop duration adjustment) per bus\n",
        "        self.action_space = spaces.Box(\n",
        "            low=-1,\n",
        "            high=1,\n",
        "            shape=(self.num_buses * 2,),  # 2 actions per bus\n",
        "            dtype=np.float32\n",
        "        )\n",
        "\n",
        "        # Dynamically set the observation space based on state columns and nearby bus features\n",
        "        num_features = len(self.state_columns) + (self.num_buses - 1) * 4  # Additional features for nearby buses\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=-np.inf,\n",
        "            high=np.inf,\n",
        "            shape=(self.num_buses, num_features),\n",
        "            dtype=np.float32\n",
        "        )\n",
        "\n",
        "        self.time_limit = time_limit\n",
        "        self.reset()\n",
        "\n",
        "    def get_bus_state(self, bus_id):\n",
        "        \"\"\"Get current state for a specific bus including nearby bus information\"\"\"\n",
        "        current_state = self.current_states[bus_id]\n",
        "\n",
        "        # Basic state features\n",
        "        state_values = current_state[self.state_columns].values.astype(np.float32)\n",
        "\n",
        "        # Get nearby bus information\n",
        "        current_pos = np.array([current_state['latitude'], current_state['longitude']])\n",
        "        nearby_features = []\n",
        "\n",
        "        for other_id, other_state in self.current_states.items():\n",
        "            if other_id != bus_id and len(nearby_features) < (self.num_buses - 1) * 4:  # 4 features per nearby bus\n",
        "                other_pos = np.array([other_state['latitude'], other_state['longitude']])\n",
        "                relative_pos = other_pos - current_pos\n",
        "                relative_speed = other_state['speed'] - current_state['speed']\n",
        "\n",
        "                nearby_features.extend([\n",
        "                    relative_pos[0],\n",
        "                    relative_pos[1],\n",
        "                    relative_speed,\n",
        "                    other_state['phase']\n",
        "                ])\n",
        "\n",
        "        # Ensure we pad nearby_features to have all buses worth of data\n",
        "        while len(nearby_features) < (self.num_buses - 1) * 4:\n",
        "            nearby_features.extend([0, 0, 0, 0])\n",
        "\n",
        "        # Combine main state features and nearby bus features\n",
        "        combined_state = np.concatenate([state_values, nearby_features])\n",
        "\n",
        "        return combined_state\n",
        "\n",
        "    def calculate_reward(self, bus_id, state, action, next_state):\n",
        "      \"\"\"Calculate reward for a single bus\"\"\"\n",
        "\n",
        "      # Initialize rewards as a dictionary\n",
        "      rewards = {\n",
        "          'schedule_adherence': 0,\n",
        "          'speed_efficiency': 0,\n",
        "          'passenger_comfort': 0,\n",
        "          'bus_spacing': 0\n",
        "      }\n",
        "\n",
        "      # Schedule adherence reward\n",
        "      stop_deviation = abs(next_state['dist_from_stop'] - state['dist_from_stop'])\n",
        "      rewards['schedule_adherence'] = -np.clip(stop_deviation / 100, 0, 1)\n",
        "\n",
        "      # Speed efficiency reward\n",
        "      optimal_speed = 10  # Hyperparameter: meters per second (about 22 mph)\n",
        "      speed_deviation = abs(next_state['speed'] - optimal_speed)\n",
        "      rewards['speed_efficiency'] = -np.clip(speed_deviation / optimal_speed, 0, 1)\n",
        "\n",
        "      # Passenger comfort reward (penalize jerky movements)\n",
        "      speed_change = abs(next_state['speed'] - state['speed'])\n",
        "      rewards['passenger_comfort'] = -np.clip(speed_change / 2, 0, 1)\n",
        "\n",
        "      # Bus spacing reward\n",
        "      nearest_distance = float('inf')\n",
        "      for other_id, other_state in self.current_states.items():\n",
        "          if other_id != bus_id:\n",
        "              dist = np.sqrt(\n",
        "                  (next_state['latitude'] - other_state['latitude'])**2 +\n",
        "                  (next_state['longitude'] - other_state['longitude'])**2\n",
        "              )\n",
        "              nearest_distance = min(nearest_distance, dist)\n",
        "\n",
        "      optimal_spacing = 0.01  # Approximately 1km in normalized coordinates\n",
        "      spacing_deviation = abs(nearest_distance - optimal_spacing)\n",
        "      rewards['bus_spacing'] = -np.clip(spacing_deviation / optimal_spacing, 0, 1)\n",
        "\n",
        "      # Weighted sum of rewards\n",
        "      weights = {\n",
        "          'schedule_adherence': 0.3,\n",
        "          'speed_efficiency': 0.3,\n",
        "          'passenger_comfort': 0.2,\n",
        "          'bus_spacing': 0.2\n",
        "      }\n",
        "\n",
        "      # Calculate total reward by applying weights to the individual reward components\n",
        "      total_reward = sum(rewards[key] * weights[key] for key in rewards)\n",
        "\n",
        "      # Ensure total_reward is a scalar value\n",
        "      return total_reward\n",
        "\n",
        "    def step(self, actions):\n",
        "      \"\"\"Environment step for all buses\"\"\"\n",
        "      self.steps_taken += 1\n",
        "      rewards = {}\n",
        "      dones = {}\n",
        "      infos = {}\n",
        "\n",
        "      # Split flattened action array back into individual bus actions\n",
        "      actions = np.split(actions, self.num_buses)\n",
        "\n",
        "      # Store current states for reward calculation\n",
        "      previous_states = self.current_states.copy()\n",
        "\n",
        "      # Update states for all buses\n",
        "      for i, bus_id in enumerate(self.bus_ids):\n",
        "          bus_id_str = str(bus_id)\n",
        "          action = actions[i]\n",
        "\n",
        "          current_idx = self.bus_indices[bus_id]\n",
        "          bus_data = self.buses_data[bus_id]\n",
        "\n",
        "          # Update index and get next state\n",
        "          self.bus_indices[bus_id] = (current_idx + 1) % len(bus_data)\n",
        "          next_state = bus_data.iloc[self.bus_indices[bus_id]].copy()\n",
        "\n",
        "          # Apply speed adjustment\n",
        "          speed_adjustment = action[0] * 2  # Scale to reasonable speed change\n",
        "          next_state['speed'] += speed_adjustment\n",
        "          next_state['speed'] = np.clip(next_state['speed'], 0, 20)  # Max 20 m/s\n",
        "\n",
        "          # Update current states\n",
        "          self.current_states[bus_id] = next_state\n",
        "\n",
        "          # Calculate rewards\n",
        "          rewards[bus_id_str] = self.calculate_reward(\n",
        "              bus_id,\n",
        "              previous_states[bus_id],\n",
        "              action,\n",
        "              next_state\n",
        "          )\n",
        "\n",
        "          dones[bus_id_str] = False\n",
        "          infos[bus_id_str] = {}\n",
        "\n",
        "      # Global done condition\n",
        "      dones['__all__'] = self.steps_taken >= self.time_limit\n",
        "\n",
        "      # Collect observations for all buses\n",
        "      observations = []\n",
        "      for bus_id in self.bus_ids:\n",
        "          bus_state = self.get_bus_state(bus_id)\n",
        "          if bus_state.shape[0] != self.observation_space.shape[1]:\n",
        "              raise ValueError(f\"Bus state shape {bus_state.shape} does not match expected feature size {self.observation_space.shape[1]}\")\n",
        "          observations.append(bus_state)\n",
        "      observations = np.stack(observations)\n",
        "\n",
        "      # Ensure observation shape consistency\n",
        "      assert observations.shape == self.observation_space.shape, \\\n",
        "          f\"Observation shape {observations.shape} does not match expected shape {self.observation_space.shape}\"\n",
        "\n",
        "      return observations, np.array(list(rewards.values())).sum(), dones, infos\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"Reset environment\"\"\"\n",
        "        self.steps_taken = 0\n",
        "        self.bus_indices = {bus_id: 0 for bus_id in self.bus_ids}\n",
        "        self.current_states = {\n",
        "            bus_id: self.buses_data[bus_id].iloc[0]\n",
        "            for bus_id in self.bus_ids\n",
        "        }\n",
        "\n",
        "        observations = np.array([\n",
        "            self.get_bus_state(bus_id)\n",
        "            for bus_id in self.bus_ids\n",
        "        ])\n",
        "        return observations\n"
      ],
      "metadata": {
        "id": "f9dC_ebwrf83"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IRL Model Definition"
      ],
      "metadata": {
        "id": "B0y8dwPGNOmi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransitFeatureExtractor(nn.Module):\n",
        "    \"\"\"Neural network for extracting features from transit state-action pairs\"\"\"\n",
        "    def __init__(self):\n",
        "        super(TransitFeatureExtractor, self).__init__()\n",
        "\n",
        "        # Input dimensions based on your columns\n",
        "        self.continuous_features = 8  # lat, long, shape_dist, dist_from_stop,\n",
        "                                    # distance_traveled, time_diff, speed, total_trip_time\n",
        "        self.phase_features = 3      # phase_0.0, phase_1.0, phase_nan\n",
        "        self.direction_features = 3  # direction_id_0.0, direction_id_1.0, direction_id_nan\n",
        "        self.headsign_features = 4   # All trip_headsign variants\n",
        "\n",
        "        # Temporal features\n",
        "        self.temporal_features = 3   # hour, day, week\n",
        "\n",
        "        # Calculate total input dimension\n",
        "        self.input_dim = (self.continuous_features + self.phase_features +\n",
        "                         self.direction_features + self.headsign_features +\n",
        "                         self.temporal_features)\n",
        "\n",
        "        # Action dimension (from your RL environment: speed adjustment and stop duration)\n",
        "        self.action_dim = 2\n",
        "\n",
        "        # Feature extraction network\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(self.input_dim + self.action_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, 64)\n",
        "        )\n",
        "\n",
        "    def forward(self, states, actions):\n",
        "        combined = torch.cat([states, actions], dim=-1)\n",
        "        return self.network(combined)\n",
        "\n",
        "class TransitStateProcessor:\n",
        "    \"\"\"Process raw transit state data into tensor format\"\"\"\n",
        "    def __init__(self):\n",
        "        self.continuous_scaler = StandardScaler()\n",
        "        self.temporal_scaler = StandardScaler()\n",
        "\n",
        "    def fit(self, data):\n",
        "        \"\"\"Fit scalers to training data\"\"\"\n",
        "        continuous_cols = [\n",
        "            'latitude', 'longitude', 'shape_dist_traveled',\n",
        "            'dist_from_stop', 'distance_traveled', 'time_diff',\n",
        "            'speed', 'total_trip_time'\n",
        "        ]\n",
        "        temporal_cols = ['hour', 'day', 'week']\n",
        "\n",
        "        self.continuous_scaler.fit(data[continuous_cols])\n",
        "        self.temporal_scaler.fit(data[temporal_cols])\n",
        "\n",
        "    def process_state(self, state):\n",
        "        \"\"\"Convert a single state to tensor format\"\"\"\n",
        "        # Extract and scale continuous features\n",
        "        continuous_features = np.array([\n",
        "            state['latitude'], state['longitude'],\n",
        "            state['shape_dist_traveled'], state['dist_from_stop'],\n",
        "            state['distance_traveled'], state['time_diff'],\n",
        "            state['speed'], state['total_trip_time']\n",
        "        ]).reshape(1, -1)\n",
        "\n",
        "        continuous_scaled = self.continuous_scaler.transform(continuous_features)\n",
        "\n",
        "        # Extract and scale temporal features\n",
        "        temporal_features = np.array([\n",
        "            state['hour'], state['day'], state['week']\n",
        "        ]).reshape(1, -1)\n",
        "\n",
        "        temporal_scaled = self.temporal_scaler.transform(temporal_features)\n",
        "\n",
        "        # Extract categorical features\n",
        "        phase_features = np.array([\n",
        "            state['phase_0.0'], state['phase_1.0'], state['phase_nan']\n",
        "        ])\n",
        "\n",
        "        direction_features = np.array([\n",
        "            state['direction_id_0.0'], state['direction_id_1.0'],\n",
        "            state['direction_id_nan']\n",
        "        ])\n",
        "\n",
        "        headsign_features = np.array([\n",
        "            state['trip_headsign_B63 39 ST - 5 AV'],\n",
        "            state['trip_headsign_B63 BAY RIDGE SHORE RD via 5 AV'],\n",
        "            state['trip_headsign_B63 PIER 6 BKLYN BRIDGE PK via 5 AV'],\n",
        "            state['trip_headsign_nan']\n",
        "        ])\n",
        "\n",
        "        # Combine all features\n",
        "        combined_features = np.concatenate([\n",
        "            continuous_scaled.flatten(),\n",
        "            temporal_scaled.flatten(),\n",
        "            phase_features,\n",
        "            direction_features,\n",
        "            headsign_features\n",
        "        ])\n",
        "\n",
        "        return torch.FloatTensor(combined_features)\n",
        "\n",
        "class MultiBusMaxEntIRL:\n",
        "    \"\"\"MaxEnt IRL implementation specifically for transit system\"\"\"\n",
        "\n",
        "    def __init__(self, env, expert_trajectories, learning_rate=0.001):\n",
        "        self.env = env\n",
        "        self.expert_trajectories = expert_trajectories\n",
        "        self.state_processor = TransitStateProcessor()\n",
        "\n",
        "        # Initialize models for each bus\n",
        "        self.feature_extractors = {}\n",
        "        self.reward_networks = {}\n",
        "        self.optimizers = {}\n",
        "\n",
        "        for bus_id in env.bus_ids:\n",
        "            self.feature_extractors[bus_id] = TransitFeatureExtractor()\n",
        "\n",
        "            # Reward network with transit-specific architecture\n",
        "            self.reward_networks[bus_id] = nn.Sequential(\n",
        "                nn.Linear(64, 32),\n",
        "                nn.ReLU(),\n",
        "                nn.BatchNorm1d(32),\n",
        "                nn.Linear(32, 16),\n",
        "                nn.ReLU(),\n",
        "                nn.BatchNorm1d(16),\n",
        "                nn.Linear(16, 1)\n",
        "            )\n",
        "\n",
        "            # Combine parameters and create optimizer\n",
        "            parameters = list(self.feature_extractors[bus_id].parameters()) + \\\n",
        "                        list(self.reward_networks[bus_id].parameters())\n",
        "\n",
        "            self.optimizers[bus_id] = optim.Adam(\n",
        "                parameters,\n",
        "                lr=learning_rate,\n",
        "                weight_decay=1e-5\n",
        "            )\n",
        "\n",
        "        # Fit state processor to expert data\n",
        "        self.fit_state_processor()\n",
        "\n",
        "    def fit_state_processor(self):\n",
        "        \"\"\"Fit the state processor to expert trajectories\"\"\"\n",
        "        all_states = []\n",
        "        for bus_trajectories in self.expert_trajectories.values():\n",
        "            for trajectory in bus_trajectories:\n",
        "                all_states.extend(trajectory['states'])\n",
        "\n",
        "        self.state_processor.fit(pd.DataFrame(all_states))\n",
        "\n",
        "    def process_trajectory(self, trajectory):\n",
        "        \"\"\"Process a trajectory into tensor format\"\"\"\n",
        "        processed_states = torch.stack([\n",
        "            self.state_processor.process_state(state)\n",
        "            for state in trajectory['states']\n",
        "        ])\n",
        "\n",
        "        processed_actions = torch.FloatTensor(trajectory['actions'])\n",
        "        return processed_states, processed_actions\n",
        "\n",
        "    def compute_reward(self, states, actions, bus_id):\n",
        "        \"\"\"Compute reward with transit-specific features\"\"\"\n",
        "        features = self.feature_extractors[bus_id](states, actions)\n",
        "        raw_rewards = self.reward_networks[bus_id](features)\n",
        "\n",
        "        # Add transit-specific reward shaping\n",
        "        schedule_adherence = torch.abs(states[:, 3])  # dist_from_stop\n",
        "        speed_efficiency = torch.abs(states[:, 6] - 10.0)  # deviation from optimal speed\n",
        "\n",
        "        shaped_rewards = raw_rewards - 0.1 * schedule_adherence - 0.05 * speed_efficiency\n",
        "        return shaped_rewards\n",
        "\n",
        "    def train(self, policy, bus_id, num_iterations=100):\n",
        "        \"\"\"MaxEnt IRL training with transit-specific considerations\"\"\"\n",
        "        # Process expert trajectories\n",
        "        expert_trajectories = self.expert_trajectories[bus_id]\n",
        "        all_expert_states = []\n",
        "        all_expert_actions = []\n",
        "\n",
        "        for trajectory in expert_trajectories:\n",
        "            states, actions = self.process_trajectory(trajectory)\n",
        "            all_expert_states.append(states)\n",
        "            all_expert_actions.append(actions)\n",
        "\n",
        "        expert_states = torch.cat(all_expert_states, dim=0)\n",
        "        expert_actions = torch.cat(all_expert_actions, dim=0)\n",
        "\n",
        "        for iteration in range(num_iterations):\n",
        "            # Forward pass with expert data\n",
        "            expert_features = self.feature_extractors[bus_id](\n",
        "                expert_states,\n",
        "                expert_actions\n",
        "            )\n",
        "            expert_rewards = self.reward_networks[bus_id](expert_features)\n",
        "\n",
        "            # Generate policy trajectories\n",
        "            policy_states = []\n",
        "            policy_actions = []\n",
        "\n",
        "            state = self.env.reset()[str(bus_id)]\n",
        "            done = False\n",
        "\n",
        "            while not done:\n",
        "                processed_state = self.state_processor.process_state(state)\n",
        "                action = policy.predict(state)[0]\n",
        "\n",
        "                policy_states.append(processed_state)\n",
        "                policy_actions.append(torch.FloatTensor(action))\n",
        "\n",
        "                next_state, _, done, _ = self.env.step({str(bus_id): action})\n",
        "                state = next_state[str(bus_id)]\n",
        "\n",
        "            policy_states = torch.stack(policy_states)\n",
        "            policy_actions = torch.stack(policy_actions)\n",
        "\n",
        "            # Compute policy features and rewards\n",
        "            policy_features = self.feature_extractors[bus_id](\n",
        "                policy_states,\n",
        "                policy_actions\n",
        "            )\n",
        "            policy_rewards = self.reward_networks[bus_id](policy_features)\n",
        "\n",
        "            # Compute MaxEnt IRL loss with regularization\n",
        "            loss = -(torch.mean(expert_rewards) - torch.mean(policy_rewards))\n",
        "\n",
        "            # Add L2 regularization\n",
        "            l2_lambda = 0.01\n",
        "            l2_norm = sum(p.pow(2.0).sum() for p in self.feature_extractors[bus_id].parameters())\n",
        "            loss = loss + l2_lambda * l2_norm\n",
        "\n",
        "            # Backward pass\n",
        "            self.optimizers[bus_id].zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizers[bus_id].step()\n",
        "\n",
        "            if (iteration + 1) % 10 == 0:\n",
        "                print(f\"Bus {bus_id} - Iteration {iteration + 1}/{num_iterations}, \"\n",
        "                      f\"Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "id": "yKbuZqN6tIYt"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining RL and IRL Models"
      ],
      "metadata": {
        "id": "bTyfnKhtUcDs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Description: Here, we define both RL and IRL models, each with distinct objectives:\n",
        "\n",
        "1.   RL Model: Learns from a reward function to make real-time adjustments to bus schedules based on performance metrics such as minimizing delay. PPO(Proximal Policy Optimization) RL algorithm is used to accomplish the task.\n",
        "2.   IRL Model: Observes historical behavior from the dataset to infer a reward structure, which guides buses to follow patterns that align with typical transit schedules. MaxEntIRL (Maximum Entropy Inverse RL) is used to accomplish the task.\n",
        "\n",
        "* Purpose: Integrating RL and IRL models enables the system to balance schedule adherence with adaptability. The RL model adjusts based on current conditions, while the IRL model keeps operations close to realistic, observed behavior."
      ],
      "metadata": {
        "id": "eEqKDOxAUlM1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate_rl_models(data):\n",
        "    \"\"\"Train and evaluate the multi-bus optimization model\"\"\"\n",
        "    # Create environment\n",
        "    env = MultiBusRouteEnv(data)\n",
        "    env = DummyVecEnv([lambda: env])\n",
        "\n",
        "    # Create PPO model for each bus\n",
        "    models = {}\n",
        "    for bus_id in df['vehicle_id'].unique():\n",
        "        models[str(bus_id)] = PPO(\n",
        "            \"MlpPolicy\",\n",
        "            env,\n",
        "            verbose=1,\n",
        "            learning_rate=3e-4,\n",
        "            n_steps=2048,\n",
        "            batch_size=64,\n",
        "            n_epochs=10,\n",
        "            gamma=0.99,\n",
        "            gae_lambda=0.95,\n",
        "            clip_range=0.2,\n",
        "            ent_coef=0.01,\n",
        "            policy_kwargs=dict(\n",
        "                net_arch=[dict(pi=[128, 64], vf=[128, 64])],\n",
        "                activation_fn=torch.nn.ReLU,\n",
        "                ortho_init=True\n",
        "            )\n",
        "        )\n",
        "\n",
        "    # Train each model\n",
        "    for bus_id, model in models.items():\n",
        "        eval_callback = EvalCallback(\n",
        "            env,\n",
        "            best_model_save_path=f\"./logs/bus_{bus_id}/\",\n",
        "            log_path=f\"./logs/bus_{bus_id}/\",\n",
        "            eval_freq=1000,\n",
        "            deterministic=True,\n",
        "            render=False\n",
        "        )\n",
        "\n",
        "        model.learn(total_timesteps=100000, callback=eval_callback)\n",
        "        model.save(f\"bus_route_model_{bus_id}_final\")\n",
        "\n",
        "    return models, env"
      ],
      "metadata": {
        "id": "ytw5irCVyniu"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train RL model\n",
        "rl_models, env = train_and_evaluate_rl_models(df)\n",
        "\n",
        "# Create expert trajectories from the processed data\n",
        "expert_trajectories = {}\n",
        "for vehicle_id, group in df.groupby('vehicle_id'):\n",
        "    # Create the list of states\n",
        "    states = group[['latitude', 'longitude', 'shape_dist_traveled', 'speed', 'stop_id',\n",
        "                    'dist_from_stop', 'distance_traveled', 'time_diff', 'total_trip_time',\n",
        "                    'hour', 'day', 'week', 'phase_0.0', 'phase_1.0', 'phase_nan',\n",
        "                    'direction_id_0.0', 'direction_id_1.0', 'direction_id_nan',\n",
        "                    'trip_headsign_B63 39 ST - 5 AV', 'trip_headsign_B63 BAY RIDGE SHORE RD via 5 AV',\n",
        "                    'trip_headsign_B63 PIER 6 BKLYN BRIDGE PK via 5 AV', 'trip_headsign_nan']].to_dict(orient='records')\n",
        "\n",
        "    # Extract actions from the df\n",
        "    actions = group[['speed', 'total_trip_time']].values.tolist()\n",
        "\n",
        "    # Store in the expert_trajectories dictionary\n",
        "    expert_trajectories[vehicle_id] = [{\n",
        "        'states': states,\n",
        "        'actions': actions\n",
        "    }]\n",
        "\n",
        "\n",
        "# Train IRL model\n",
        "irl_model = MultiBusMaxEntIRL(env, expert_trajectories)\n",
        "for bus_id in df['vehicle_id'].unique():\n",
        "  irl_model.train(rl_models[bus_id], bus_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQ3qjCoh1bee",
        "outputId": "2da926ef-0070-4c03-8397-1adb9db09f86",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/policies.py:486: UserWarning: As shared layers in the mlp_extractor are removed since SB3 v1.8.0, you should now pass directly a dictionary and not a list (net_arch=dict(pi=..., vf=...) instead of net_arch=[dict(pi=..., vf=...)])\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Using cpu device\n",
            "Using cpu device\n",
            "Using cpu device\n",
            "Using cpu device\n",
            "Using cpu device\n",
            "Using cpu device\n",
            "Using cpu device\n",
            "Using cpu device\n",
            "Using cpu device\n",
            "Using cpu device\n",
            "Using cpu device\n",
            "Using cpu device\n",
            "Using cpu device\n",
            "Using cpu device\n",
            "Using cpu device\n",
            "Using cpu device\n",
            "Using cpu device\n",
            "Using cpu device\n",
            "Using cpu device\n",
            "Using cpu device\n",
            "Using cpu device\n",
            "Using cpu device\n",
            "Using cpu device\n",
            "Using cpu device\n",
            "Using cpu device\n",
            "Using cpu device\n",
            "Using cpu device\n",
            "Using cpu device\n",
            "Using cpu device\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=1000, episode_reward=-14.09 +/- 0.00\n",
            "Episode length: 1.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1        |\n",
            "|    mean_reward     | -14.1    |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 1000     |\n",
            "---------------------------------\n",
            "New best mean reward!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Combining RL and IRL Models"
      ],
      "metadata": {
        "id": "kej7JPJuNUo3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Description: This section combines the decision-making policies of RL and IRL models to form a unified strategy. The combine_rl_irl_transit function merges actions from both models, with weights that dynamically adjust based on the bus’s deviation from its planned schedule. When far from the planned schedule, the RL policy is prioritized; when closer, IRL behavior dominates.\n",
        "* Purpose: This combined approach leverages the strengths of both RL and IRL, balancing real-time adjustments with adherence to historical patterns. This results in more flexible yet predictable bus operations, improving schedule reliability and minimizing delays."
      ],
      "metadata": {
        "id": "Q3rlHM1hVmcG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def combine_rl_irl_transit(rl_models, irl_model, env, alpha=0.5):\n",
        "    \"\"\"Combine RL and IRL models with transit-specific considerations\"\"\"\n",
        "\n",
        "    class TransitCombinedPolicy:\n",
        "        def __init__(self, rl_model, reward_function, alpha):\n",
        "            self.rl_model = rl_model\n",
        "            self.reward_function = reward_function\n",
        "            self.alpha = alpha\n",
        "            self.state_processor = irl_model.state_processor\n",
        "\n",
        "        def predict(self, state, deterministic=True):\n",
        "            # Get RL model's action\n",
        "            rl_action, _ = self.rl_model.predict(state, deterministic=deterministic)\n",
        "\n",
        "            # Process state for IRL evaluation\n",
        "            processed_state = self.state_processor.process_state(state)\n",
        "\n",
        "            # Generate additional candidate actions around RL action\n",
        "            candidate_actions = [\n",
        "                rl_action,\n",
        "                rl_action * 0.8,  # Slower option\n",
        "                rl_action * 1.2   # Faster option\n",
        "            ]\n",
        "\n",
        "            # Evaluate all actions\n",
        "            combined_scores = []\n",
        "            for action in candidate_actions:\n",
        "                # Get RL score\n",
        "                rl_score = self.rl_model.policy.evaluate_actions(\n",
        "                    torch.FloatTensor(state).unsqueeze(0),\n",
        "                    torch.FloatTensor(action).unsqueeze(0)\n",
        "                )[0].item()\n",
        "\n",
        "                # Get IRL score\n",
        "                irl_score = self.reward_function(\n",
        "                    processed_state.unsqueeze(0),\n",
        "                    torch.FloatTensor(action).unsqueeze(0)\n",
        "                ).item()\n",
        "\n",
        "                # Combine scores with transit-specific weighting\n",
        "                schedule_deviation = abs(state['dist_from_stop'])\n",
        "                if schedule_deviation > 100:  # If far from schedule\n",
        "                    alpha = max(0.7, self.alpha)  # Increase RL weight\n",
        "                else:\n",
        "                    alpha = self.alpha\n",
        "\n",
        "                combined_score = alpha * rl_score + (1 - alpha) * irl_score\n",
        "                combined_scores.append(combined_score)\n",
        "\n",
        "            # Select best action\n",
        "            best_idx = np.argmax(combined_scores)\n",
        "            return candidate_actions[best_idx]\n",
        "\n",
        "    # Create combined policies\n",
        "    combined_policies = {}\n",
        "    for bus_id in env.bus_ids:\n",
        "        reward_function = lambda s, a, bid=bus_id: irl_model.compute_reward(s, a, bid)\n",
        "        combined_policies[bus_id] = TransitCombinedPolicy(\n",
        "            rl_models[bus_id],\n",
        "            reward_function,\n",
        "            alpha\n",
        "        )\n",
        "\n",
        "    return combined_policies"
      ],
      "metadata": {
        "id": "q32OecmH8lEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict the Optimal Policy"
      ],
      "metadata": {
        "id": "1xn1C3DNQDoR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Description: This section builds a MultiBusPolicyPredictor, a model that can predict optimal actions for multiple buses using the combined RL and IRL policies. It evaluates the models’ effectiveness in improving bus schedules by running simulations and comparing performance metrics like delay reduction and adherence to the schedule.\n",
        "* Purpose: By testing and evaluating the combined policy on multiple bus lines, we can assess the effectiveness of our model in real-world applications. This predictor offers insights into how well the combined approach can generalize across different transit lines, highlighting areas for future model improvement."
      ],
      "metadata": {
        "id": "PHyHPTdoVwoq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiBusPolicyPredictor:\n",
        "    \"\"\"Predict actions for a multi-bus transit system using combined RL and IRL policies.\"\"\"\n",
        "\n",
        "    def __init__(self, env, combined_policies):\n",
        "        \"\"\"\n",
        "        Initializes the policy predictor.\n",
        "\n",
        "        Args:\n",
        "            env: The transit environment containing state and bus information.\n",
        "            combined_policies: A dictionary of TransitCombinedPolicy objects for each bus.\n",
        "        \"\"\"\n",
        "        self.env = env\n",
        "        self.combined_policies = combined_policies  # Combined policies for each bus\n",
        "\n",
        "    def predict_action(self, bus_id, state):\n",
        "        \"\"\"\n",
        "        Predict the best action for a specific bus using the combined RL-IRL policy.\n",
        "\n",
        "        Args:\n",
        "            bus_id: The ID of the bus for which to predict the action.\n",
        "            state: The current state of the bus.\n",
        "\n",
        "        Returns:\n",
        "            The selected action for the bus.\n",
        "        \"\"\"\n",
        "        policy = self.combined_policies[bus_id]\n",
        "        action = policy.predict(state)\n",
        "        return action\n",
        "\n",
        "    def predict_all_actions(self, state):\n",
        "        \"\"\"\n",
        "        Predict actions for all buses in the current environment state.\n",
        "\n",
        "        Args:\n",
        "            state: The current state of the environment containing all bus states.\n",
        "\n",
        "        Returns:\n",
        "            An array of actions, one for each bus in the environment.\n",
        "        \"\"\"\n",
        "        actions = []\n",
        "        for bus_id in self.env.bus_ids:\n",
        "            bus_state = state[bus_id]\n",
        "            action = self.predict_action(bus_id, bus_state)\n",
        "            actions.append(action)\n",
        "        return np.array(actions)\n",
        "\n",
        "    def evaluate_policy(self, num_episodes=10):\n",
        "        \"\"\"\n",
        "        Evaluate the combined RL-IRL policy over multiple episodes.\n",
        "\n",
        "        Args:\n",
        "            num_episodes: Number of episodes to run for evaluation.\n",
        "\n",
        "        Returns:\n",
        "            The mean and standard deviation of rewards per episode.\n",
        "        \"\"\"\n",
        "        rewards_per_episode = []\n",
        "        for _ in range(num_episodes):\n",
        "            total_reward = 0\n",
        "            state = self.env.reset()\n",
        "            done = False\n",
        "            while not done:\n",
        "                actions = self.predict_all_actions(state)\n",
        "                state, reward, done, _ = self.env.step(actions)\n",
        "                total_reward += reward\n",
        "            rewards_per_episode.append(total_reward)\n",
        "        return np.mean(rewards_per_episode), np.std(rewards_per_episode)"
      ],
      "metadata": {
        "id": "-k5XSqaL10N5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_policies = combine_rl_irl_transit(rl_models, irl_model, env, alpha=0.5)\n",
        "policy_predictor = MultiBusPolicyPredictor(env, combined_policies)\n",
        "\n",
        "# Predict actions for a given state\n",
        "state = env.reset()\n",
        "actions = policy_predictor.predict_all_actions(state)\n",
        "print(\"Predicted Actions:\", actions)\n",
        "\n",
        "# Evaluate the combined policy\n",
        "mean_reward, std_reward = policy_predictor.evaluate_policy(num_episodes=10)\n",
        "print(\"Mean Reward:\", mean_reward)\n",
        "print(\"Reward Std Dev:\", std_reward)"
      ],
      "metadata": {
        "id": "HeHKs-07QNfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Performance Metrics and Analytics"
      ],
      "metadata": {
        "id": "EFfvNHy8V-b7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Description: This final segment assesses the model’s performance using various metrics, such as average delay, schedule deviation, and efficiency scores. It may include plotting results to visualize the effect of the combined policy on bus punctuality and route efficiency.\n",
        "* Purpose: Performance metrics are essential for evaluating the success of the model. By understanding how well the combined policy reduces delays and improves schedule adherence, we can quantify the impact of the RL and IRL approach on transit optimization."
      ],
      "metadata": {
        "id": "Akbd6PyiWCcR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_true_actions_and_timestamps(df):\n",
        "    \"\"\"\n",
        "    Extracts the true actions and timestamps from the bus data DataFrame.\n",
        "\n",
        "    Args:\n",
        "    - df (pd.DataFrame): DataFrame containing bus route data.\n",
        "\n",
        "    Returns:\n",
        "    - true_actions (list): List of true action values based on `dist_from_stop`.\n",
        "    - timestamps (list): List of timestamps associated with each action.\n",
        "    \"\"\"\n",
        "    # Sort by timestamp to ensure chronological order\n",
        "    df = df.sort_values(by='timestamp')\n",
        "\n",
        "    # Extract true actions and timestamps\n",
        "    true_actions = df['dist_from_stop'].tolist()\n",
        "    timestamps = pd.to_datetime(df['timestamp']).tolist()\n",
        "\n",
        "    return true_actions, timestamps\n",
        "\n",
        "\n",
        "def evaluate_policy_performance(predicted_actions, true_actions, timestamps):\n",
        "    \"\"\"\n",
        "    Evaluate the performance of the combined RL-IRL policy.\n",
        "\n",
        "    Args:\n",
        "    - predicted_actions: A list of actions predicted by the combined policy for each time step.\n",
        "    - true_actions: A list of true actions (or ideal actions) for each time step.\n",
        "    - timestamps: A list of timestamps associated with each action.\n",
        "\n",
        "    Returns:\n",
        "    - performance_metrics: A dictionary containing calculated performance metrics.\n",
        "    - deviations: A list of schedule deviations over time.\n",
        "    \"\"\"\n",
        "    # Calculate absolute schedule deviations (difference between predicted and true actions)\n",
        "    deviations = [abs(pred - true) for pred, true in zip(predicted_actions, true_actions)]\n",
        "\n",
        "    # Calculate average delay (average absolute difference)\n",
        "    avg_delay = np.mean(deviations)\n",
        "\n",
        "    # Calculate max deviation for severe cases\n",
        "    max_deviation = np.max(deviations)\n",
        "\n",
        "    # Calculate efficiency score as inverse of average delay\n",
        "    efficiency_score = 1 / (1 + avg_delay)  # Higher score is better\n",
        "\n",
        "    # Compile metrics\n",
        "    performance_metrics = {\n",
        "        'Average Delay': avg_delay,\n",
        "        'Max Deviation': max_deviation,\n",
        "        'Efficiency Score': efficiency_score\n",
        "    }\n",
        "\n",
        "    return performance_metrics, deviations\n",
        "\n",
        "def plot_performance_metrics(deviations, timestamps):\n",
        "    \"\"\"\n",
        "    Plot the deviations and analyze the effectiveness of the combined policy.\n",
        "\n",
        "    Args:\n",
        "    - deviations: List of schedule deviations for each timestamp.\n",
        "    - timestamps: List of timestamps associated with each deviation.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Plot deviations over time\n",
        "    plt.plot(timestamps, deviations, label='Schedule Deviation', color='blue', linestyle='--')\n",
        "    plt.xlabel('Timestamp')\n",
        "    plt.ylabel('Deviation (from ideal schedule)')\n",
        "    plt.title('Schedule Deviation Over Time')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Extract true actions and timestamps from dataframe\n",
        "true_actions, timestamps = extract_true_actions_and_timestamps(df)\n",
        "\n",
        "# Compute performance metrics\n",
        "performance_metrics, deviations = evaluate_policy_performance(actions, true_actions, timestamps)\n",
        "\n",
        "# Display performance metrics\n",
        "print(\"Performance Metrics:\")\n",
        "for metric, value in performance_metrics.items():\n",
        "    print(f\"{metric}: {value:.2f}\")\n",
        "\n",
        "# Plot schedule deviations over time\n",
        "plot_performance_metrics(deviations, timestamps)"
      ],
      "metadata": {
        "id": "GuhOKUKMV9XS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}